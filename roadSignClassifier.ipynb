{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# For using the Roadsign Classifier Web App, go to the following link : https://59bc-34-74-152-238.ngrok-free.app/\n",
        "\n",
        "If the link changes, just go to the link generated by the forth code block, which is the same code block above the next main header. For running the code on a new Google Colab session, you need to create a free account with ngrok and add your authtoken. If Running in Google Colab, create a secret with the name 'ngrok' with the value as your authtoken. For updating the code on the server, run all the code blocks"
      ],
      "metadata": {
        "id": "x4i8QMbclorJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install streamlit\n",
        "!pip install pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_7cIlmri5LH",
        "outputId": "1ed65c97-786d-4958-f789-a9a3039cfd59"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (11.3.0)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.50.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.5.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "secret = userdata.get('ngrok')\n",
        "!ngrok authtoken $secret # MUST UNCOMMENT LINE AND ADD AUTHTOKEN TO RUN FRONT END"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj8WWdwO37Jw",
        "outputId": "e0e787b9-5502-443c-c3b6-04ca0b7f3301"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "### Current Iteration of Model ###\n",
        "\n",
        "### How to Use Model\n",
        "### 1. Upload .png of roadsign to colab file storage\n",
        "### 2. change image_path variable to be the name of the roadsign file\n",
        "# Update the image path to your image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from google.colab.patches import cv2_imshow  # Use this to display images in Colab\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "\n",
        "# Ensure Tesseract is properly set up\n",
        "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Update if necessary\n",
        "\n",
        "def detect_road_sign(image):\n",
        "    original_height, original_width = image.shape[:2]\n",
        "\n",
        "    # Convert to BGR if the input is in RGB\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGBA2BGR)\n",
        "\n",
        "    # Resize the image for better processing\n",
        "    image_resized = cv2.resize(image, (600, 400))\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian Blur to reduce noise\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Perform edge detection using Canny\n",
        "    edged = cv2.Canny(blurred, 50, 150)\n",
        "\n",
        "    # Convert to HSV\n",
        "    hsv = cv2.cvtColor(image_resized, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Define color ranges\n",
        "    lower_red1 = np.array([0, 70, 50])\n",
        "    upper_red1 = np.array([10, 255, 255])\n",
        "    lower_red2 = np.array([170, 70, 50])\n",
        "    upper_red2 = np.array([180, 255, 255])\n",
        "    lower_white = np.array([0, 0, 200])\n",
        "    upper_white = np.array([180, 30, 255])\n",
        "    lower_yellow = np.array([20, 100, 100])\n",
        "    upper_yellow = np.array([30, 255, 255])\n",
        "\n",
        "    # Threshold the HSV image for colors\n",
        "    mask_red = cv2.bitwise_or(cv2.inRange(hsv, lower_red1, upper_red1),\n",
        "                              cv2.inRange(hsv, lower_red2, upper_red2))\n",
        "    mask_white = cv2.inRange(hsv, lower_white, upper_white)\n",
        "    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
        "\n",
        "    # Clean up masks with morphological operations\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    mask_red = cv2.morphologyEx(mask_red, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    mask_red = cv2.dilate(mask_red, kernel, iterations=1)\n",
        "    mask_white = cv2.morphologyEx(mask_white, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    mask_white = cv2.dilate(mask_white, kernel, iterations=1)\n",
        "    mask_yellow = cv2.morphologyEx(mask_yellow, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    mask_yellow = cv2.dilate(mask_yellow, kernel, iterations=1)\n",
        "\n",
        "    # Detect Stop Signs and No Parking Signs\n",
        "    contours_red, _ = cv2.findContours(mask_red, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for contour in contours_red:\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area > 500:\n",
        "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "            x, y, w, h = cv2.boundingRect(approx)\n",
        "            aspect_ratio = float(w) / h\n",
        "            perimeter = cv2.arcLength(contour, True)\n",
        "            circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
        "\n",
        "            if circularity > 0.7:  # Circular shapes (for No Parking signs)\n",
        "                roi = image_resized[y:y + h, x:x + w]\n",
        "                roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "                _, binary_roi = cv2.threshold(roi_gray, 50, 255, cv2.THRESH_BINARY_INV)\n",
        "                custom_config = r'--psm 6'\n",
        "                detected_text = pytesseract.image_to_string(binary_roi, config=custom_config)\n",
        "                if 'P' in detected_text or \"NO PARKING\" in detected_text.upper():\n",
        "                    cv2.rectangle(image_resized, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
        "                    cv2.putText(image_resized, \"No Parking Sign\", (x, y - 10),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "\n",
        "                elif len(approx) == 8 and 0.8 < aspect_ratio < 1.2:\n",
        "                    cv2.drawContours(image_resized, [approx], 0, (0, 0, 255), 3)\n",
        "                    cv2.putText(image_resized, \"Stop Sign\", (x, y - 10),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
        "\n",
        "\n",
        "\n",
        "    # Detect Speed Limit Signs\n",
        "    contours_white, _ = cv2.findContours(mask_white, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for contour in contours_white:\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area > 1000:\n",
        "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "            x, y, w, h = cv2.boundingRect(approx)\n",
        "            aspect_ratio = float(w) / h\n",
        "            if len(approx) == 4 and 0.5 < aspect_ratio < 1.5:\n",
        "                cv2.drawContours(image_resized, [approx], 0, (255, 0, 0), 3)\n",
        "                cv2.putText(image_resized, \"Speed Limit Sign\", (x, y - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
        "\n",
        "    # Detect Yield Signs\n",
        "    contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for contour in contours:\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area > 800:\n",
        "            epsilon = 0.04 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "            if len(approx) == 3:\n",
        "                x, y, w, h = cv2.boundingRect(approx)\n",
        "                aspect_ratio = float(w) / h\n",
        "                if 0.5 < aspect_ratio < 1.5:\n",
        "                    cv2.drawContours(image_resized, [approx], 0, (0, 255, 255), 3)\n",
        "                    cv2.putText(image_resized, \"Yield Sign\", (x, y - 10),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
        "\n",
        "    # Detect Railroad Crossing Signs\n",
        "    contours_yellow, _ = cv2.findContours(mask_yellow, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    # List to store bounding boxes for merging\n",
        "    bounding_boxes = []\n",
        "\n",
        "    for contour in contours_yellow:\n",
        "        # Filter smaller contours to avoid noise\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area > 500:  # Lowered the area threshold for detecting smaller or dim regions\n",
        "            # Approximate the contour\n",
        "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "\n",
        "            # Check if the contour is roughly circular\n",
        "            x, y, w, h = cv2.boundingRect(approx)\n",
        "            aspect_ratio = float(w) / h\n",
        "            if 0.7 < aspect_ratio < 1.3:  # Allow a broader range for aspect ratio\n",
        "                # Check the circularity\n",
        "                perimeter = cv2.arcLength(contour, True)\n",
        "                circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
        "                if circularity > 0.6:  # Lowered the circularity threshold for imperfect circles\n",
        "                    bounding_boxes.append((x, y, w, h))\n",
        "\n",
        "    # Merge bounding boxes into a single region\n",
        "    if bounding_boxes:\n",
        "        x_min = min([x for x, y, w, h in bounding_boxes])\n",
        "        y_min = min([y for x, y, w, h in bounding_boxes])\n",
        "        x_max = max([x + w for x, y, w, h in bounding_boxes])\n",
        "        y_max = max([y + h for x, y, w, h in bounding_boxes])\n",
        "\n",
        "        # Extract the merged bounding box\n",
        "        roi = image_resized[y_min:y_max, x_min:x_max]\n",
        "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "        _, binary_roi = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY_INV)  # Lowered the binary threshold\n",
        "\n",
        "        # Detect lines or 'X' shape in the ROI\n",
        "        edges = cv2.Canny(binary_roi, 30, 120)  # Adjusted edge detection thresholds\n",
        "        lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=25, minLineLength=20, maxLineGap=10)\n",
        "\n",
        "        if lines is not None and len(lines) >= 4:  # Expect at least 4 lines for 'X'\n",
        "            cv2.rectangle(image_resized, (x_min, y_min), (x_max, y_max), (0, 255, 0), 3)\n",
        "            cv2.putText(image_resized, \"Railroad Crossing\", (x_min, y_min - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "\n",
        "    image_resized = cv2.cvtColor(image_resized, cv2.COLOR_RGBA2BGR)\n",
        "    image_resized = cv2.resize(image_resized, (original_width, original_height))\n",
        "\n",
        "    return image_resized\n",
        "\n",
        "# Streamlit GUI\n",
        "st.title(\"Road Sign Detector\")\n",
        "st.write(\"By Austin McCormick\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose a road sign image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Read the uploaded image\n",
        "    image = Image.open(uploaded_file)\n",
        "    image_np = np.array(image)  # Convert to numpy array\n",
        "\n",
        "    # Process the image using the detection function\n",
        "    processed_image = detect_road_sign(image_np)\n",
        "\n",
        "    # Display the original and processed images\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.image(image, caption=\"Uploaded Image\", use_container_width=True)\n",
        "    with col2:\n",
        "        st.image(processed_image, caption=\"Processed Image\", use_container_width=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqfTEZ5K3CSZ",
        "outputId": "da653694-5cd5-430c-fee1-a00d656c779e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "!streamlit run app.py &>/content/logs.txt &\n",
        "public_url = ngrok.connect(8501, \"http\")  # Explicitly specify HTTP protocol\n",
        "\n",
        "print(f\"Streamlit app running at {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seONLGas3GBc",
        "outputId": "483e5b27-204c-4e9f-eba9-ebea13549906"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app running at NgrokTunnel: \"https://a32ef50741f9.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ALL CODE BELOW HERE IS PAST ITERATIONS AND TEST CODE**"
      ],
      "metadata": {
        "id": "pRbFTKRj_QYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from google.colab.patches import cv2_imshow  # Use this to display images in Colab\n",
        "\n",
        "# Ensure Tesseract is properly set up\n",
        "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Update if necessary\n",
        "\n",
        "def detect_road_sign(image_path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(\"Error: Unable to load the image.\")\n",
        "        return\n",
        "\n",
        "    # Resize the image for better processing\n",
        "    image_resized = cv2.resize(image, (600, 400))\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian Blur to reduce noise\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Perform edge detection using Canny\n",
        "    edged = cv2.Canny(blurred, 50, 150)\n",
        "\n",
        "    # Convert to HSV\n",
        "    hsv = cv2.cvtColor(image_resized, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Define color ranges\n",
        "    lower_red1 = np.array([0, 70, 50])\n",
        "    upper_red1 = np.array([10, 255, 255])\n",
        "    lower_red2 = np.array([170, 70, 50])\n",
        "    upper_red2 = np.array([180, 255, 255])\n",
        "    lower_white = np.array([0, 0, 200])\n",
        "    upper_white = np.array([180, 30, 255])\n",
        "    lower_yellow = np.array([20, 100, 100])\n",
        "    upper_yellow = np.array([30, 255, 255])\n",
        "\n",
        "    # Threshold the HSV image for colors\n",
        "    mask_red = cv2.bitwise_or(cv2.inRange(hsv, lower_red1, upper_red1),\n",
        "                              cv2.inRange(hsv, lower_red2, upper_red2))\n",
        "    mask_white = cv2.inRange(hsv, lower_white, upper_white)\n",
        "    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
        "\n",
        "    # Clean up masks with morphological operations\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    mask_red = cv2.morphologyEx(mask_red, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    mask_red = cv2.dilate(mask_red, kernel, iterations=1)\n",
        "    mask_white = cv2.morphologyEx(mask_white, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    mask_white = cv2.dilate(mask_white, kernel, iterations=1)\n",
        "    mask_yellow = cv2.morphologyEx(mask_yellow, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    mask_yellow = cv2.dilate(mask_yellow, kernel, iterations=1)\n",
        "\n",
        "    # Detect Stop Signs and No Parking Signs\n",
        "    contours_red, _ = cv2.findContours(mask_red, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for contour in contours_red:\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area > 500:\n",
        "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "            x, y, w, h = cv2.boundingRect(approx)\n",
        "            aspect_ratio = float(w) / h\n",
        "            perimeter = cv2.arcLength(contour, True)\n",
        "            circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
        "\n",
        "            if circularity > 0.7:  # Circular shapes (for No Parking signs)\n",
        "                roi = image_resized[y:y + h, x:x + w]\n",
        "                roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "                _, binary_roi = cv2.threshold(roi_gray, 50, 255, cv2.THRESH_BINARY_INV)\n",
        "                custom_config = r'--psm 6'\n",
        "                detected_text = pytesseract.image_to_string(binary_roi, config=custom_config)\n",
        "                if 'P' in detected_text or \"NO PARKING\" in detected_text.upper():\n",
        "                    cv2.rectangle(image_resized, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
        "                    cv2.putText(image_resized, \"No Parking Sign\", (x, y - 10),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "\n",
        "                elif len(approx) == 8 and 0.8 < aspect_ratio < 1.2:\n",
        "                    cv2.drawContours(image_resized, [approx], 0, (0, 0, 255), 3)\n",
        "                    cv2.putText(image_resized, \"Stop Sign\", (x, y - 10),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
        "\n",
        "\n",
        "\n",
        "    # Detect Speed Limit Signs\n",
        "    contours_white, _ = cv2.findContours(mask_white, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for contour in contours_white:\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area > 1000:\n",
        "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "            x, y, w, h = cv2.boundingRect(approx)\n",
        "            aspect_ratio = float(w) / h\n",
        "            if len(approx) == 4 and 0.5 < aspect_ratio < 1.5:\n",
        "                cv2.drawContours(image_resized, [approx], 0, (255, 0, 0), 3)\n",
        "                cv2.putText(image_resized, \"Speed Limit Sign\", (x, y - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
        "\n",
        "    # Detect Yield Signs\n",
        "    contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for contour in contours:\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area > 800:\n",
        "            epsilon = 0.04 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "            if len(approx) == 3:\n",
        "                x, y, w, h = cv2.boundingRect(approx)\n",
        "                aspect_ratio = float(w) / h\n",
        "                if 0.5 < aspect_ratio < 1.5:\n",
        "                    cv2.drawContours(image_resized, [approx], 0, (0, 255, 255), 3)\n",
        "                    cv2.putText(image_resized, \"Yield Sign\", (x, y - 10),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
        "\n",
        "    # Detect Railroad Crossing Signs\n",
        "    contours_yellow, _ = cv2.findContours(mask_yellow, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    # List to store bounding boxes for merging\n",
        "    bounding_boxes = []\n",
        "\n",
        "    for contour in contours_yellow:\n",
        "        # Filter smaller contours to avoid noise\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area > 500:  # Lowered the area threshold for detecting smaller or dim regions\n",
        "            # Approximate the contour\n",
        "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "\n",
        "            # Check if the contour is roughly circular\n",
        "            x, y, w, h = cv2.boundingRect(approx)\n",
        "            aspect_ratio = float(w) / h\n",
        "            if 0.7 < aspect_ratio < 1.3:  # Allow a broader range for aspect ratio\n",
        "                # Check the circularity\n",
        "                perimeter = cv2.arcLength(contour, True)\n",
        "                circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
        "                if circularity > 0.6:  # Lowered the circularity threshold for imperfect circles\n",
        "                    bounding_boxes.append((x, y, w, h))\n",
        "\n",
        "    # Merge bounding boxes into a single region\n",
        "    if bounding_boxes:\n",
        "        x_min = min([x for x, y, w, h in bounding_boxes])\n",
        "        y_min = min([y for x, y, w, h in bounding_boxes])\n",
        "        x_max = max([x + w for x, y, w, h in bounding_boxes])\n",
        "        y_max = max([y + h for x, y, w, h in bounding_boxes])\n",
        "\n",
        "        # Extract the merged bounding box\n",
        "        roi = image_resized[y_min:y_max, x_min:x_max]\n",
        "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "        _, binary_roi = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY_INV)  # Lowered the binary threshold\n",
        "\n",
        "        # Detect lines or 'X' shape in the ROI\n",
        "        edges = cv2.Canny(binary_roi, 30, 120)  # Adjusted edge detection thresholds\n",
        "        lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=25, minLineLength=20, maxLineGap=10)\n",
        "\n",
        "        if lines is not None and len(lines) >= 4:  # Expect at least 4 lines for 'X'\n",
        "            cv2.rectangle(image_resized, (x_min, y_min), (x_max, y_max), (0, 255, 0), 3)\n",
        "            cv2.putText(image_resized, \"Railroad Crossing\", (x_min, y_min - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "\n",
        "    # Display the output\n",
        "    cv2_imshow(image_resized)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Update the image path\n",
        "image_path = \"speedlimit_real.PNG\"\n",
        "detect_road_sign(image_path)\n",
        "'''"
      ],
      "metadata": {
        "id": "oN4QXT7R2dOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PKe3TT7ML9w"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "### Sketch Roadsign Detection for Stop signs, Yield signs, and Speedlimit signs ###\n",
        "### Code for real roadsign detection from images further below ###\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pytesseract\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def remove_writing(img_path):\n",
        "        img = cv2.imread(img_path)\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Binarize the image using thresholding\n",
        "        _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        filled_image = img.copy()\n",
        "\n",
        "        for contour in contours:\n",
        "            if cv2.contourArea(contour) > 500:\n",
        "                # Dilate the contour area slightly to expand the filled area\n",
        "                mask = np.zeros_like(binary)\n",
        "                cv2.drawContours(mask, [contour], -1, 255, thickness=cv2.FILLED)\n",
        "                dilated_mask = cv2.dilate(mask, np.ones((3, 3), np.uint8), iterations=1)\n",
        "\n",
        "                # Fill the dilated contour with white\n",
        "                filled_image[dilated_mask == 255] = [255, 255, 255]\n",
        "\n",
        "                # Redraw the contour outline with a thick line to reinforce the border\n",
        "                cv2.drawContours(filled_image, [contour], -1, (0, 0, 0), thickness=2)\n",
        "        return filled_image\n",
        "\n",
        "class HeuristicRoadSignRecognizer:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def recognize_sign(self, image_path):\n",
        "        # Check if the file exists\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"Error: The file '{image_path}' was not found.\")\n",
        "            return \"File not found\", {}\n",
        "\n",
        "        # Load the image in grayscale\n",
        "\n",
        "        img = remove_writing(image_path)\n",
        "\n",
        "        # Check if the image was loaded correctly\n",
        "        if img is None:\n",
        "            print(f\"Error: Unable to load image '{image_path}'. Please check the file format.\")\n",
        "            return \"Image load error\", {}\n",
        "\n",
        "        # Preprocessing: Apply binary threshold\n",
        "        _, img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        # Apply Gaussian blur to smooth edges\n",
        "        img = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "\n",
        "        # Apply morphological operations to remove small noise\n",
        "        kernel = np.ones((3, 3), np.uint8)\n",
        "        img = cv2.erode(img, kernel, iterations=1)\n",
        "        img = cv2.dilate(img, kernel, iterations=1)\n",
        "        if len(img.shape) == 3:  # Check if image has 3 channels\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Display the original image\n",
        "        original_img = cv2.imread(image_path)  # Load the original image\n",
        "        original_img_rgb = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "\n",
        "        plt.imshow(original_img_rgb)\n",
        "        plt.title(\"Original Sketch:\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "        # Display the preprocessed image\n",
        "        plt.imshow(img, cmap=\"gray\")\n",
        "        plt.title(\"Preprocessed Sketch for Corner Detection:\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "        # Calculate heuristic features\n",
        "        features = {}\n",
        "\n",
        "        # Feature 1: Aspect Ratio\n",
        "        height, width = img.shape\n",
        "        features[\"aspect_ratio\"] = width / height\n",
        "\n",
        "        # Feature 2: Fill Density (number of black pixels)\n",
        "        num_black_pixels = np.sum(img == 0)\n",
        "        features[\"fill_density\"] = num_black_pixels / (height * width)\n",
        "\n",
        "        # Feature 3: Symmetry\n",
        "        half_width = width // 2\n",
        "        vertical_symmetry = np.sum(img[:, :half_width] == np.fliplr(img[:, width - half_width:])) / (height * half_width)\n",
        "        horizontal_symmetry = np.sum(img[:height // 2, :] == np.flipud(img[height - height // 2:, :])) / ((height // 2) * width)\n",
        "        features[\"vertical_symmetry\"] = vertical_symmetry\n",
        "        features[\"horizontal_symmetry\"] = horizontal_symmetry\n",
        "\n",
        "        # Feature 4: Corner Detection\n",
        "        corners_harris = cv2.goodFeaturesToTrack(img, maxCorners=50, qualityLevel=0.01, minDistance=400, useHarrisDetector=True, k=0.1)\n",
        "        num_corners_harris = len(corners_harris) if corners_harris is not None else 0\n",
        "        features[\"num_corners\"] = num_corners_harris\n",
        "        corners_display = np.intp(corners_harris)\n",
        "\n",
        "        # Create a colored copy of the grayscale image for corner visualization\n",
        "        color_image = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "        # Iterate through detected corners\n",
        "        if corners_harris is not None:\n",
        "            corners_display = np.intp(corners_harris)\n",
        "            for c in corners_display:\n",
        "                x, y = c.ravel()\n",
        "                # Highlight corners in a different color (e.g., red)\n",
        "                cv2.circle(color_image, center=(x, y), radius=10, color=(0, 0, 255), thickness=-1)\n",
        "\n",
        "        # Display the image with corners\n",
        "        plt.imshow(cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(\"Detected Corner Locations:\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "        # Feature 5: Edge Density\n",
        "        edges = cv2.Canny(img, 100, 200)\n",
        "        edge_density = np.sum(edges == 255) / (height * width)\n",
        "        features[\"edge_density\"] = edge_density\n",
        "\n",
        "        # Feature 6: Orientation Detection (for distinguishing triangle orientation)\n",
        "        contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if len(contours) > 0:\n",
        "            # Get the largest contour assuming it's the sign shape\n",
        "            largest_contour = max(contours, key=cv2.contourArea)\n",
        "            M = cv2.moments(largest_contour)\n",
        "            if M[\"m00\"] != 0:\n",
        "                centroid_y = int(M[\"m01\"] / M[\"m00\"])\n",
        "                x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "                bounding_box_center_y = y + h / 2\n",
        "\n",
        "                # Determine if the centroid is in the upper or lower half of the bounding box\n",
        "                if centroid_y < bounding_box_center_y:\n",
        "                    orientation = \"inverted\"  # Likely a yield sign (inverted triangle)\n",
        "                else:\n",
        "                    orientation = \"upright\"  # Likely a warning sign (upright triangle)\n",
        "            else:\n",
        "                orientation = \"unknown\"\n",
        "        else:\n",
        "            orientation = \"unknown\"\n",
        "\n",
        "        features[\"orientation\"] = orientation\n",
        "\n",
        "        # Feature 7: Line Detection (Presence of horizontal/vertical lines)\n",
        "        num_horizontal_lines = 0\n",
        "        num_vertical_lines = 0\n",
        "        lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=50, minLineLength=30, maxLineGap=10)\n",
        "        if lines is not None:\n",
        "            for line in lines:\n",
        "                x1, y1, x2, y2 = line[0]\n",
        "                if abs(y2 - y1) < 5:  # Horizontal line\n",
        "                    num_horizontal_lines += 1\n",
        "                elif abs(x2 - x1) < 5:  # Vertical line\n",
        "                    num_vertical_lines += 1\n",
        "        features[\"horizontal_lines\"] = num_horizontal_lines\n",
        "        features[\"vertical_lines\"] = num_vertical_lines\n",
        "\n",
        "        # Feature 8: Proportion of Filled Area (Bounding Box)\n",
        "        bounding_box_area = w * h\n",
        "        features[\"filled_area_proportion\"] = num_black_pixels / bounding_box_area\n",
        "\n",
        "        # Recognize based on heuristic rules\n",
        "        if features[\"num_corners\"] == 3:\n",
        "            if features[\"orientation\"] == \"upright\":\n",
        "                sign_type = \"Warning (Triangle)\"\n",
        "            elif features[\"orientation\"] == \"inverted\":\n",
        "                sign_type = \"Yield Sign\"\n",
        "            else:\n",
        "                sign_type = \"Unknown Triangle Sign\"\n",
        "        elif features[\"num_corners\"] == 8:\n",
        "            sign_type = \"Stop Sign\"\n",
        "        #elif features[\"fill_density\"] > 0.5 and features[\"num_corners\"] == 0:\n",
        "        elif features[\"num_corners\"] < 3:\n",
        "            sign_type = \"Speed Limit Sign\"\n",
        "        else:\n",
        "            sign_type = \"Unknown Sign\"\n",
        "\n",
        "        return sign_type, features\n",
        "\n",
        "# Example usage\n",
        "recognizer = HeuristicRoadSignRecognizer()\n",
        "sign_type, extracted_features = recognizer.recognize_sign(\"yield3.png\")\n",
        "print(\"Recognized sign type:\", sign_type)\n",
        "print(\"\\nExtracted features:\", extracted_features)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "### Test code to clean out sign interiors for preprocessing ###\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the image\n",
        "img = cv2.imread('yield3.png')\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Binarize the image using thresholding\n",
        "_, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "# Detect contours\n",
        "contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Create a copy of the original image to draw filled shapes and highlights\n",
        "filled_image = img.copy()\n",
        "\n",
        "# Loop over each detected contour\n",
        "for contour in contours:\n",
        "    # Optionally, filter contours by area to avoid small noise\n",
        "    if cv2.contourArea(contour) > 500:  # Adjust the threshold as needed\n",
        "        # Dilate the contour area slightly to expand the filled area\n",
        "        mask = np.zeros_like(binary)\n",
        "        cv2.drawContours(mask, [contour], -1, 255, thickness=cv2.FILLED)\n",
        "        dilated_mask = cv2.dilate(mask, np.ones((3, 3), np.uint8), iterations=1)\n",
        "\n",
        "        # Fill the dilated contour with white on the main image\n",
        "        filled_image[dilated_mask == 255] = [255, 255, 255]\n",
        "\n",
        "        # Redraw the contour outline with a thick line to reinforce the border\n",
        "        cv2.drawContours(filled_image, [contour], -1, (0, 0, 0), thickness=2)  # Black border\n",
        "\n",
        "\n",
        "\n",
        "# Display the result\n",
        "cv2_imshow(filled_image)\n",
        "'''"
      ],
      "metadata": {
        "id": "Rq6SCEDGvTbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "### test code, ML approach that uses cascade classifier xml files ###\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow  # For displaying images in Google Colab\n",
        "\n",
        "# Load the Stop Sign Cascade Classifier XML\n",
        "stop_sign = cv2.CascadeClassifier('cascade_stop_sign.xml')\n",
        "\n",
        "def detect_stop_sign(image_path):\n",
        "    # Load the image\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Could not load the image at path: {image_path}\")\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect the stop sign\n",
        "    stop_sign_scaled = stop_sign.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "    # Draw rectangles around detected stop signs and annotate\n",
        "    for (x, y, w, h) in stop_sign_scaled:\n",
        "        # Draw rectangle around the stop sign\n",
        "        stop_sign_rectangle = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
        "        # Write \"Stop Sign\" below the rectangle\n",
        "        cv2.putText(img=stop_sign_rectangle,\n",
        "                    text=\"Stop Sign\",\n",
        "                    org=(x, y + h + 30),\n",
        "                    fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    fontScale=1,\n",
        "                    color=(0, 0, 255),\n",
        "                    thickness=2,\n",
        "                    lineType=cv2.LINE_4)\n",
        "\n",
        "    # Display the result\n",
        "    cv2_imshow(img)\n",
        "\n",
        "# Example usage\n",
        "uploaded_image_path = \"stopsign_real.png\"  # Replace with the path to your uploaded PNG image\n",
        "detect_stop_sign(uploaded_image_path)\n",
        "'''"
      ],
      "metadata": {
        "id": "rYOEmM8ppikd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from google.colab.patches import cv2_imshow  # Use this to display images in Colab\n",
        "\n",
        "# Ensure Tesseract is properly set up\n",
        "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Update if necessary\n",
        "\n",
        "def detect_road_sign(image_path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(\"Error: Unable to load the image.\")\n",
        "        return\n",
        "\n",
        "    # Resize the image for better processing\n",
        "    image_resized = cv2.resize(image, (600, 400))\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian Blur to reduce noise\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Perform edge detection using Canny\n",
        "    edged = cv2.Canny(blurred, 50, 150)\n",
        "\n",
        "    # Convert to HSV\n",
        "    hsv = cv2.cvtColor(image_resized, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Define color ranges\n",
        "    lower_red1 = np.array([0, 70, 50])\n",
        "    upper_red1 = np.array([10, 255, 255])\n",
        "    lower_red2 = np.array([170, 70, 50])\n",
        "    upper_red2 = np.array([180, 255, 255])\n",
        "    lower_white = np.array([0, 0, 200])\n",
        "    upper_white = np.array([180, 30, 255])\n",
        "    lower_yellow = np.array([20, 100, 100])\n",
        "    upper_yellow = np.array([30, 255, 255])\n",
        "\n",
        "    # Threshold the HSV image for colors\n",
        "    mask_red = cv2.bitwise_or(cv2.inRange(hsv, lower_red1, upper_red1),\n",
        "                              cv2.inRange(hsv, lower_red2, upper_red2))\n",
        "    mask_white = cv2.inRange(hsv, lower_white, upper_white)\n",
        "    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
        "\n",
        "    # Clean up masks with morphological operations\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    mask_red = cv2.morphologyEx(mask_red, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    mask_red = cv2.dilate(mask_red, kernel, iterations=1)\n",
        "    mask_white = cv2.morphologyEx(mask_white, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    mask_white = cv2.dilate(mask_white, kernel, iterations=1)\n",
        "    mask_yellow = cv2.morphologyEx(mask_yellow, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    mask_yellow = cv2.dilate(mask_yellow, kernel, iterations=1)\n",
        "\n",
        "    # Detect Stop Signs and No Parking Signs\n",
        "    contours_red, _ = cv2.findContours(mask_red, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for contour in contours_red:\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area > 500:\n",
        "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "            x, y, w, h = cv2.boundingRect(approx)\n",
        "            aspect_ratio = float(w) / h\n",
        "            perimeter = cv2.arcLength(contour, True)\n",
        "            circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
        "\n",
        "            if circularity > 0.7:  # Circular shapes (for No Parking signs)\n",
        "                roi = image_resized[y:y + h, x:x + w]\n",
        "                roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "                _, binary_roi = cv2.threshold(roi_gray, 50, 255, cv2.THRESH_BINARY_INV)\n",
        "                custom_config = r'--psm 6'\n",
        "                detected_text = pytesseract.image_to_string(binary_roi, config=custom_config)\n",
        "                if 'P' in detected_text or \"NO PARKING\" in detected_text.upper():\n",
        "                    cv2.rectangle(image_resized, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
        "                    cv2.putText(image_resized, \"No Parking Sign\", (x, y - 10),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "\n",
        "                elif len(approx) == 8 and 0.8 < aspect_ratio < 1.2:\n",
        "                    cv2.drawContours(image_resized, [approx], 0, (0, 0, 255), 3)\n",
        "                    cv2.putText(image_resized, \"Stop Sign\", (x, y - 10),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
        "\n",
        "\n",
        "\n",
        "    # Detect Speed Limit Signs\n",
        "    contours_white, _ = cv2.findContours(mask_white, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for contour in contours_white:\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area > 1000:\n",
        "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "            x, y, w, h = cv2.boundingRect(approx)\n",
        "            aspect_ratio = float(w) / h\n",
        "            if len(approx) == 4 and 0.5 < aspect_ratio < 1.5:\n",
        "                cv2.drawContours(image_resized, [approx], 0, (255, 0, 0), 3)\n",
        "                cv2.putText(image_resized, \"Speed Limit Sign\", (x, y - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
        "\n",
        "    # Detect Yield Signs\n",
        "    contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for contour in contours:\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area > 800:\n",
        "            epsilon = 0.04 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "            if len(approx) == 3:\n",
        "                x, y, w, h = cv2.boundingRect(approx)\n",
        "                aspect_ratio = float(w) / h\n",
        "                if 0.5 < aspect_ratio < 1.5:\n",
        "                    cv2.drawContours(image_resized, [approx], 0, (0, 255, 255), 3)\n",
        "                    cv2.putText(image_resized, \"Yield Sign\", (x, y - 10),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
        "\n",
        "    # Detect Railroad Crossing Signs\n",
        "    contours_yellow, _ = cv2.findContours(mask_yellow, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for contour in contours_yellow:\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area > 1000:\n",
        "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "            x, y, w, h = cv2.boundingRect(approx)\n",
        "            aspect_ratio = float(w) / h\n",
        "            perimeter = cv2.arcLength(contour, True)\n",
        "            circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
        "            if 0.8 < aspect_ratio < 1.2 and circularity > 0.7:\n",
        "                cv2.rectangle(image_resized, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
        "                cv2.putText(image_resized, \"Railroad Crossing\", (x, y - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "\n",
        "    # Display the output\n",
        "    cv2_imshow(image_resized)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Update the image path\n",
        "image_path = \"stopsign_real3.PNG\"\n",
        "detect_road_sign(image_path)\n",
        "'''"
      ],
      "metadata": {
        "id": "BvUtLS9uzbyI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}